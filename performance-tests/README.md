# ‚ö° Pruebas de Rendimiento y Estr√©s - E-commerce Microservices

## üìã Resumen Ejecutivo

Este documento describe la implementaci√≥n completa de pruebas de rendimiento y estr√©s para el sistema de microservicios de e-commerce utilizando **Locust**. Las pruebas cubren todos los microservicios principales y simulan casos de uso reales del sistema.

### üéØ Objetivos

- **Medir el rendimiento** del sistema bajo diferentes cargas de trabajo
- **Identificar cuellos de botella** en microservicios individuales
- **Validar la escalabilidad** del sistema
- **Establecer m√©tricas de referencia** para el rendimiento
- **Detectar problemas de rendimiento** antes del despliegue en producci√≥n

---

## üèóÔ∏è Arquitectura de Pruebas

### Microservicios Evaluados

| Microservicio | Puerto | Funcionalidad Principal | Endpoints Evaluados |
|---------------|--------|-------------------------|-------------------|
| **API Gateway** | 8080 | Punto de entrada √∫nico | Routing, Load Balancing |
| **User Service** | 8700 | Gesti√≥n de usuarios | CRUD usuarios, credenciales |
| **Product Service** | 8500 | Cat√°logo de productos | CRUD productos, categor√≠as |
| **Order Service** | 8300 | Gesti√≥n de pedidos | CRUD pedidos, carritos |
| **Payment Service** | 8400 | Procesamiento de pagos | CRUD pagos, estados |
| **Favourite Service** | 8800 | Productos favoritos | CRUD favoritos |
| **Shipping Service** | 8600 | Gesti√≥n de env√≠os | CRUD items de pedido |

### Tipos de Usuarios Simulados

1. **EcommerceUser** - Usuario t√≠pico de e-commerce
2. **HeavyUser** - Usuario intensivo con m√∫ltiples operaciones
3. **LightUser** - Usuario con operaciones m√≠nimas
4. **StressTestUser** - Usuario para pruebas de estr√©s

---

## üìä M√©tricas Evaluadas

### M√©tricas de Rendimiento

- **Tiempo de Respuesta**
  - Promedio
  - Mediana (P50)
  - Percentil 90 (P90)
  - Percentil 95 (P95)
  - Percentil 99 (P99)
  - M√°ximo

- **Throughput**
  - Requests por segundo
  - Requests por usuario
  - Picos de throughput

- **Tasa de Errores**
  - Porcentaje de requests fallidos
  - Tipos de errores
  - Distribuci√≥n temporal de errores

### M√©tricas de Recursos

- **CPU Usage** - Utilizaci√≥n del procesador
- **Memory Usage** - Uso de memoria
- **Network I/O** - Tr√°fico de red
- **Database Connections** - Conexiones a base de datos

---

## üß™ Escenarios de Prueba

### 1. Pruebas de Rendimiento Normal

**Objetivo**: Evaluar el rendimiento bajo carga t√≠pica de producci√≥n

```bash
# Configuraci√≥n
Usuarios: 20
Spawn Rate: 2 usuarios/segundo
Duraci√≥n: 10 minutos
Distribuci√≥n: 75% normales, 15% pesados, 10% ligeros

# Ejecuci√≥n
./run_tests.sh performance ecommerce 20 2 10m
```

**M√©tricas Esperadas**:
- P95 Response Time: < 2000ms
- Error Rate: < 1%
- Throughput: > 50 req/s

### 2. Pruebas de Carga Pico

**Objetivo**: Simular per√≠odos de alta demanda (Black Friday)

```bash
# Configuraci√≥n
Usuarios: 100
Spawn Rate: 10 usuarios/segundo
Duraci√≥n: 15 minutos
Distribuci√≥n: 60% normales, 30% pesados, 10% ligeros

# Ejecuci√≥n
./run_tests.sh performance ecommerce 100 10 15m
```

**M√©tricas Esperadas**:
- P95 Response Time: < 5000ms
- Error Rate: < 5%
- Throughput: > 200 req/s

### 3. Pruebas de Carga Sostenida

**Objetivo**: Validar estabilidad durante operaci√≥n continua

```bash
# Configuraci√≥n
Usuarios: 50
Spawn Rate: 5 usuarios/segundo
Duraci√≥n: 1 hora
Distribuci√≥n: 70% normales, 20% pesados, 10% ligeros

# Ejecuci√≥n
./run_tests.sh performance ecommerce 50 5 1h
```

**M√©tricas Esperadas**:
- P95 Response Time: < 3000ms
- Error Rate: < 2%
- Throughput: > 100 req/s

### 4. Pruebas de Estr√©s

**Objetivo**: Encontrar el punto de ruptura del sistema

```bash
# Configuraci√≥n
Usuarios: 200
Spawn Rate: 20 usuarios/segundo
Duraci√≥n: 20 minutos
Distribuci√≥n: 100% usuarios de estr√©s

# Ejecuci√≥n
./run_tests.sh stress ecommerce 200 20 20m
```

**M√©tricas Esperadas**:
- P95 Response Time: < 10000ms
- Error Rate: < 10%
- Throughput: > 500 req/s

### 5. Pruebas de Microservicios Individuales

**Objetivo**: Identificar cuellos de botella espec√≠ficos

```bash
# User Service
./run_tests.sh performance user-service 30 3 10m

# Product Service
./run_tests.sh performance product-service 40 4 10m

# Order Service
./run_tests.sh performance order-service 25 2 10m

# Payment Service
./run_tests.sh performance payment-service 20 2 10m

# Favourite Service
./run_tests.sh performance favourite-service 35 3 10m

# Shipping Service
./run_tests.sh performance shipping-service 20 2 10m
```

---

## üöÄ Instalaci√≥n y Configuraci√≥n

### Prerrequisitos

- Python 3.8+
- pip3
- Docker y Docker Compose
- Microservicios ejecut√°ndose

### Instalaci√≥n

```bash
# 1. Navegar al directorio de pruebas
cd performance-tests

# 2. Instalar dependencias
./run_tests.sh install

# 3. Verificar que los servicios est√©n ejecut√°ndose
./run_tests.sh check
```

### Dependencias

```txt
locust==2.17.0
requests==2.31.0
faker==19.6.2
pandas==2.1.1
matplotlib==3.7.2
seaborn==0.12.2
```

---

## üìà Casos de Uso Simulados

### Flujo de Usuario T√≠pico

1. **Navegaci√≥n de Productos** (40% del tr√°fico)
   - Listar productos
   - Ver detalles de producto
   - Buscar por categor√≠a

2. **Gesti√≥n de Favoritos** (25% del tr√°fico)
   - Agregar productos a favoritos
   - Ver lista de favoritos
   - Remover favoritos

3. **Proceso de Compra** (20% del tr√°fico)
   - Crear pedido
   - Procesar pago
   - Ver historial de pedidos

4. **Gesti√≥n de Usuario** (15% del tr√°fico)
   - Crear cuenta
   - Actualizar perfil
   - Gestionar credenciales

### Patrones de Carga

- **Horario Pico**: 9:00-11:00 y 19:00-21:00
- **Horario Valle**: 2:00-6:00
- **Fin de Semana**: Carga m√°s alta en s√°bados
- **Eventos Especiales**: Black Friday, Cyber Monday

---

## üìä An√°lisis de Resultados

### Interpretaci√≥n de M√©tricas

#### Tiempo de Respuesta

| Percentil | Interpretaci√≥n | Acci√≥n Recomendada |
|-----------|----------------|-------------------|
| P50 < 500ms | Excelente | Mantener configuraci√≥n |
| P95 < 2000ms | Bueno | Monitorear tendencias |
| P95 > 5000ms | Cr√≠tico | Optimizar inmediatamente |

#### Throughput

| Valor | Interpretaci√≥n | Acci√≥n Recomendada |
|-------|----------------|-------------------|
| > 200 req/s | Excelente | Escalar horizontalmente |
| 50-200 req/s | Bueno | Monitorear recursos |
| < 50 req/s | Cr√≠tico | Investigar cuellos de botella |

#### Tasa de Errores

| Valor | Interpretaci√≥n | Acci√≥n Recomendada |
|-------|----------------|-------------------|
| < 1% | Excelente | Mantener configuraci√≥n |
| 1-5% | Aceptable | Investigar errores espec√≠ficos |
| > 5% | Cr√≠tico | Resolver problemas inmediatamente |

### Identificaci√≥n de Cuellos de Botella

1. **Base de Datos**
   - Queries lentas
   - Conexiones agotadas
   - √çndices faltantes

2. **Red**
   - Latencia alta
   - Ancho de banda limitado
   - Timeouts de conexi√≥n

3. **Aplicaci√≥n**
   - C√≥digo ineficiente
   - Recursos no liberados
   - Algoritmos lentos

4. **Infraestructura**
   - CPU saturada
   - Memoria insuficiente
   - Disco I/O alto

---

## üîß Configuraci√≥n Avanzada

### Variables de Entorno

```bash
# Configuraci√≥n de Locust
export LOCUST_HOST="http://localhost:8080"
export LOCUST_USERS="50"
export LOCUST_SPAWN_RATE="5"
export LOCUST_RUN_TIME="10m"

# Configuraci√≥n de reportes
export REPORT_FORMAT="html,csv,json"
export REPORT_INCLUDE_CHARTS="true"
```

### Personalizaci√≥n de Pruebas

```python
# Ejemplo: Personalizar comportamiento de usuario
class CustomEcommerceUser(EcommerceUser):
    wait_time = between(0.5, 2)  # Tiempo de espera personalizado
    
    @task(15)
    def custom_product_search(self):
        # Implementar b√∫squeda personalizada
        pass
```

---

## üìã Checklist de Pruebas

### Antes de Ejecutar Pruebas

- [ ] Todos los microservicios est√°n ejecut√°ndose
- [ ] Base de datos est√° poblada con datos de prueba
- [ ] Red est√° estable y sin limitaciones
- [ ] Recursos del sistema est√°n disponibles
- [ ] Monitoreo est√° configurado

### Durante las Pruebas

- [ ] Monitorear m√©tricas en tiempo real
- [ ] Verificar logs de errores
- [ ] Observar uso de recursos
- [ ] Documentar comportamientos an√≥malos

### Despu√©s de las Pruebas

- [ ] Generar reportes completos
- [ ] Analizar resultados
- [ ] Identificar cuellos de botella
- [ ] Documentar recomendaciones
- [ ] Planificar optimizaciones

---

## üö® Troubleshooting

### Problemas Comunes

#### 1. Servicios No Responden

```bash
# Verificar estado de servicios
./run_tests.sh check

# Reiniciar servicios si es necesario
cd ../scripts
./stop-services.sh
./start-services.sh
```

#### 2. Errores de Conexi√≥n

```bash
# Verificar conectividad
curl -f http://localhost:8080/app/actuator/health

# Verificar puertos
netstat -tlnp | grep :8080
```

#### 3. Rendimiento Degradado

```bash
# Verificar recursos del sistema
top
htop
iostat
```

#### 4. Errores de Memoria

```bash
# Verificar memoria disponible
free -h
df -h
```

### Logs y Debugging

```bash
# Ver logs de Locust
tail -f locust.log

# Ver logs de microservicios
docker logs <container_name>

# Ver logs del sistema
journalctl -f
```

---

## üìà Mejores Pr√°cticas

### 1. Planificaci√≥n de Pruebas

- **Definir objetivos** claros antes de ejecutar
- **Establecer m√©tricas de referencia** basadas en requisitos
- **Planificar diferentes escenarios** de carga
- **Documentar expectativas** y tolerancias

### 2. Ejecuci√≥n de Pruebas

- **Ejecutar pruebas incrementales** (carga baja a alta)
- **Monitorear recursos** durante las pruebas
- **Documentar condiciones** del entorno
- **Ejecutar m√∫ltiples iteraciones** para validar consistencia

### 3. An√°lisis de Resultados

- **Comparar con m√©tricas de referencia**
- **Identificar patrones** en los datos
- **Correlacionar m√©tricas** de diferentes niveles
- **Documentar hallazgos** y recomendaciones

### 4. Optimizaci√≥n Continua

- **Implementar mejoras** basadas en resultados
- **Re-ejecutar pruebas** despu√©s de optimizaciones
- **Establecer monitoreo continuo** en producci√≥n
- **Actualizar m√©tricas de referencia** regularmente

---

## üîÑ Integraci√≥n con CI/CD

### Pipeline de Pruebas

```yaml
# Ejemplo de pipeline Jenkins/GitHub Actions
stages:
  - name: "Performance Tests"
    steps:
      - name: "Install Dependencies"
        run: "./run_tests.sh install"
      
      - name: "Check Services"
        run: "./run_tests.sh check"
      
      - name: "Run Quick Tests"
        run: "./run_tests.sh performance ecommerce 20 2 5m"
      
      - name: "Generate Report"
        run: "./generate_report.py --test-name ecommerce --timestamp $TIMESTAMP"
      
      - name: "Archive Results"
        run: "tar -czf performance_results.tar.gz results/"
```

### Criterios de Aceptaci√≥n

```bash
# Script de validaci√≥n autom√°tica
#!/bin/bash
ERROR_RATE=$(grep "Error rate" results/ecommerce_*.csv | awk '{print $2}')
RESPONSE_TIME=$(grep "95%" results/ecommerce_*.csv | awk '{print $2}')

if [ $(echo "$ERROR_RATE > 0.05" | bc) -eq 1 ]; then
    echo "ERROR: Error rate too high: $ERROR_RATE"
    exit 1
fi

if [ $(echo "$RESPONSE_TIME > 5000" | bc) -eq 1 ]; then
    echo "ERROR: Response time too high: $RESPONSE_TIME"
    exit 1
fi

echo "Performance tests passed!"
```

---

## üìö Referencias y Recursos

### Documentaci√≥n Oficial

- [Locust Documentation](https://docs.locust.io/)
- [Spring Boot Actuator](https://docs.spring.io/spring-boot/docs/current/reference/html/actuator.html)
- [Docker Compose](https://docs.docker.com/compose/)

### Herramientas de Monitoreo

- **APM**: New Relic, Datadog, AppDynamics
- **Logs**: ELK Stack, Splunk, Fluentd
- **M√©tricas**: Prometheus, Grafana, InfluxDB
- **Tracing**: Jaeger, Zipkin, OpenTelemetry

### Recursos Adicionales

- [Performance Testing Best Practices](https://martinfowler.com/articles/nonDeterminism.html)
- [Microservices Performance Patterns](https://microservices.io/patterns/microservices.html)
- [Load Testing Strategies](https://www.thoughtworks.com/radar/techniques/load-testing)

---

## üìû Soporte y Contacto

Para preguntas, problemas o sugerencias relacionadas con las pruebas de rendimiento:

- **Documentaci√≥n**: Este archivo README
- **Issues**: Crear un issue en el repositorio
- **Discusiones**: Usar las discusiones del repositorio

---

**√öltima actualizaci√≥n**: $(date)
**Versi√≥n**: 1.0.0
**Autor**: Equipo de Desarrollo
